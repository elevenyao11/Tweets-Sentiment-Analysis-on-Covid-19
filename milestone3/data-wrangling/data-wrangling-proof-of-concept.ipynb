{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "megaCov-data-collection-proof-of-concept.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YCMX_u99PMB"
      },
      "source": [
        "# Data Collection Proof-of-Concept\n",
        "##  -- Mega-Cov Hydrator\n",
        "\n",
        "The Google Colab notebook shows to to hydrate an Mega-cov archive.\n",
        "\n",
        "You need to run this on Google Colab to get tweet metadata including its text.\n",
        "\n",
        "The demo below hydrates 1 month of Mega-Cov data, filter it by Country == Canada, Australia, etc. & Language == English. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjHK1NVR_cM6"
      },
      "source": [
        "# Initializaition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acjblhY9_ghH"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "%pip install twarc\n",
        "%pip install jsonlines\n",
        "# %pip install wget\n",
        "%pip install jsonlines\n",
        "clear_output()\n",
        "\n",
        "import os\n",
        "from google.colab import drive \n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "# import wget\n",
        "import json\n",
        "import jsonlines\n",
        "import tqdm\n",
        "from twarc import Twarc\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtnFLQK6_hzx"
      },
      "source": [
        "# shared archive -> \"local\" archive\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKit86WE-N-8"
      },
      "source": [
        "Follow these steps:\n",
        "\n",
        "1. Go to your Googe Drive\n",
        "2. Create a folder named `MegaCov` \n",
        "3. Locate a Mega-cov archive file from [here](https://github.com/UBC-NLP/megacov/tree/master/tweet_ids) \n",
        "4. Add it to the `MegaCov` folder you just created in your Google Drive.\n",
        "\n",
        "\n",
        "Now run the cell below.\n",
        "\n",
        "When prompted, grant acess."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJjCtkzm9iol",
        "outputId": "dfb21846-b9e9-4733-b460-0a7fcb424096"
      },
      "source": [
        "\n",
        "drive.mount('/content/gdrive')\n",
        "clear_output()\n",
        "working_directory = 'My Drive/MegaCov'\n",
        "\n",
        "wd=\"/content/gdrive/\"+working_directory\n",
        "os.chdir(wd)\n",
        "\n",
        "dirpath = os.getcwd()\n",
        "print(\"current directory is : \" + dirpath)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "current directory is : /content/gdrive/My Drive/MegaCov\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea2BgxtP4PyP"
      },
      "source": [
        "# archive -> json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vogjrpZ9-zku"
      },
      "source": [
        "path = os.path.join(wd, \"tweet_ids\") \n",
        "if not os.path.exists('./tweet_ids'):\n",
        "  try:\n",
        "    os.makedirs(path)\n",
        "    # os.chdir('tweet_ids')\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn_WJUOTCR9Q"
      },
      "source": [
        "os.chdir('tweet_ids')\n",
        "# !pwd"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MZ7djiHCetJ",
        "outputId": "0dae8855-7bc6-4b00-e126-716ed1fb1b42"
      },
      "source": [
        "!tar -xvf  'MagaCOV_Apr_2020.tar.gz' -C './tweet_ids'\n",
        "#TODO unzip in batch *.tar.gz files"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4_2020_1.json\n",
            "4_2020_2.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L3cIGXD4Wvq"
      },
      "source": [
        "#  json  + filter -> tweet_ids"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6msB_MGYD1c3"
      },
      "source": [
        "os.chdir('tweet_ids')\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQ2rFiaqGQb0",
        "outputId": "bdf74a46-20e8-44ab-8445-9ad1f8716605"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/MegaCov/tweet_ids\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evz7vElyin-h",
        "outputId": "4c3fbee2-e44f-4365-c176-fc19f681db46"
      },
      "source": [
        "!ls\n",
        "\n",
        "# file = '5_2020_1.json'\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5_2020_1.json  5_2020_2.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw20wVdWj2jf"
      },
      "source": [
        "# list of countries we research:\n",
        "ctrs = ['Canada',\n",
        "        'United States',\n",
        "        'Mexico',\n",
        "        'Austrialia',\n",
        "        'New Zealand',\n",
        "        'United Kingdom',\n",
        "        'France']"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJnLgVwSiQSE",
        "outputId": "656f5e73-292d-44cc-ea09-3f47afba34cc"
      },
      "source": [
        "directory =  os.getcwd()\n",
        "twt_ids = []\n",
        "cnt = 0\n",
        "\n",
        "for root,dirs,files in os.walk(directory):\n",
        "    for file in files:\n",
        "        if file.endswith(\".json\"):\n",
        "            with jsonlines.open(file) as reader:\n",
        "                for obj in reader:\n",
        "\n",
        "                    cnt += 1\n",
        "                    \n",
        "                    #  filter by country and by Language:\n",
        "                    if obj['LangID_tool'] == 'en':\n",
        "                        if obj['country'] in ctrs: \n",
        "                            twt_ids.append(obj['tweet_id'])\n",
        "\n",
        "print('\\n done!')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIbx1WyBjKN_",
        "outputId": "faf22e67-1ae2-4031-9f67-6e0e06a118da"
      },
      "source": [
        "len(twt_ids)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "170891"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnTFBt78592l"
      },
      "source": [
        "# tweet_ids -> txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Afa5dD_y6E_k"
      },
      "source": [
        "#@title Enter ID output file {run: \"auto\"}\n",
        "os.chdir(wd)\n",
        "final_tweet_ids_filename = \"ids_2020Apr.txt\" #@param {type: \"string\"}\n",
        "# The set of IDs is stored in this file.\n",
        "with open(final_tweet_ids_filename, \"w+\") as f:\n",
        "    for id in twt_ids:\n",
        "        f.write('%s\\n' % id)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDEcRpe84_Ex"
      },
      "source": [
        "# Hydrate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRqkjBkPD-C6"
      },
      "source": [
        "#@title Insert API Keys here { run : \"auto\"}\n",
        "from twarc import Twarc\n",
        "\n",
        "# These keys are received after applying for a twitter developer account\n",
        "\n",
        "consumer_key = \"\" #@param {type:\"string\"}\n",
        "consumer_secret = \"\" #@param {type:\"string\"}\n",
        "access_token = \"\" #@param {type:\"string\"}\n",
        "access_token_secret = \"\" #@param {type:\"string\"}\n",
        "\n",
        "t = Twarc(consumer_key, consumer_secret, access_token, access_token_secret)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOW5TDdUEPTh"
      },
      "source": [
        "#@title Set up Directory { run: \"auto\"}\n",
        "input_filename_tweet_ids = \"ids_2020Apr.txt\" #@param {type: \"string\"}\n",
        "output_filename = \"hydrated_2020Apr.tsv\" #@param {type: \"string\"}"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AHSRPAT0TUd",
        "outputId": "8e9accb3-0078-47ca-89a3-14b43be6b3fe"
      },
      "source": [
        "# Stores hydrated tweets here as jsonl objects\n",
        "# Contains one json object per line\n",
        "output_json_filename = output_filename[:output_filename.index(\".\")] + \".jsonl\"\n",
        "ids = []\n",
        "with open(final_tweet_ids_filename, \"r\") as ids_file:\n",
        "    ids = ids_file.read().split()\n",
        "hydrated_tweets = []\n",
        "ids_to_hydrate = set(ids)\n",
        "\n",
        "# Looks at the output file for already hydrated tweets\n",
        "if os.path.isfile(output_json_filename):\n",
        "    with jsonlines.open(output_json_filename, \"r\") as reader:\n",
        "        for i in reader.iter(type=dict, skip_invalid=True):\n",
        "            # These tweets have already been hydrated. So remove them from ids_to_hydrate\n",
        "            hydrated_tweets.append(i)\n",
        "            ids_to_hydrate.remove(i[\"id_str\"])\n",
        "print(\"Total IDs: \" + str(len(ids)) + \", IDs to hydrate: \" + str(len(ids_to_hydrate)))\n",
        "print(\"Hydrated: \" + str(len(hydrated_tweets)))\n",
        "\n",
        "count = len(hydrated_tweets)\n",
        "start_index = count # The index from where tweets haven't been saved to the output_json_file\n",
        "# Stores hydrated tweets to output_json_file every num_save iterations.\n",
        "num_save  = 1000\n",
        "\n",
        "# Now, use twarc and start hydrating\n",
        "for tweet in t.hydrate(ids_to_hydrate):\n",
        "    hydrated_tweets.append(tweet)\n",
        "    count += 1\n",
        "    # If num_save iterations have passed,\n",
        "    if (count % num_save) == 0:\n",
        "        # Open the output file\n",
        "        # NOTE: Even if the code stops during IO, only tweets from the current iteration are lost.\n",
        "        # Older tweets are preserved as the file is written in append mode.\n",
        "        with jsonlines.open(output_json_filename, \"a\") as writer:\n",
        "            print(\"Started IO\")\n",
        "            # Now write the tweets from start_index. The other tweets don't have to be written\n",
        "            # as they were already written in a previous iteration or run.\n",
        "            for hydrated_tweet in hydrated_tweets[start_index:]:\n",
        "                writer.write(hydrated_tweet)\n",
        "            print(\"Finished IO\")\n",
        "        print(\"Saved \" + str(count) + \" hydrated tweets.\")\n",
        "        # Now, since everything has been written. Reset start_index\n",
        "        start_index = count\n",
        "# There might be tweets unwritten in the last iteration if the count is not a multiple of num_tweets.\n",
        "# In that case, just write out the remainder of tweets.\n",
        "if count != start_index:\n",
        "    print(\"Here with start_index\", start_index)\n",
        "    with jsonlines.open(output_json_filename, \"a\") as writer:\n",
        "        for hydrated_tweet in hydrated_tweets[start_index:]:\n",
        "           writer.write(hydrated_tweet)  \n",
        "print('\\n done!') "
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total IDs: 170891, IDs to hydrate: 170891\n",
            "Hydrated: 0\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 1000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 2000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 3000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 4000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 5000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 6000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 7000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 8000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 9000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 10000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 11000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 12000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 13000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 14000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 15000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 16000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 17000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 18000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 19000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 20000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 21000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 22000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 23000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 24000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 25000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 26000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 27000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 28000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 29000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 30000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 31000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 32000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 33000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 34000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 35000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 36000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 37000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 38000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 39000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 40000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 41000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 42000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 43000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 44000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 45000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 46000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 47000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 48000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 49000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 50000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 51000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 52000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 53000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 54000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 55000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 56000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 57000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 58000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 59000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 60000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 61000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 62000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 63000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 64000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 65000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 66000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 67000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 68000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 69000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 70000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 71000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 72000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 73000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 74000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 75000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 76000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 77000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 78000 hydrated tweets.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:twarc:rate limit exceeded: sleeping 286.39680337905884 secs\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Started IO\n",
            "Finished IO\n",
            "Saved 79000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 80000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 81000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 82000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 83000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 84000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 85000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 86000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 87000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 88000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 89000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 90000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 91000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 92000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 93000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 94000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 95000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 96000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 97000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 98000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 99000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 100000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 101000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 102000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 103000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 104000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 105000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 106000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 107000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 108000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 109000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 110000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 111000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 112000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 113000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 114000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 115000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 116000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 117000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 118000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 119000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 120000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 121000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 122000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 123000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 124000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 125000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 126000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 127000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 128000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 129000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 130000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 131000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 132000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 133000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 134000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 135000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 136000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 137000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 138000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 139000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 140000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 141000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 142000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 143000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 144000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 145000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 146000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 147000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 148000 hydrated tweets.\n",
            "Here with start_index 148000\n",
            "\n",
            " done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjz_B2eOoPzH",
        "outputId": "db1fc7b6-ac4a-4c11-d57d-f83efb7b4fd3"
      },
      "source": [
        "print('next...')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "next...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkfhAuHH6q4g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ca72c9a-c6fb-4f66-c02f-16622b9688dc"
      },
      "source": [
        "# Convert jsonl to tsv\n",
        "import csv, jsonlines\n",
        "output_json_filename = output_filename[:output_filename.index(\".\")] + \".jsonl\"\n",
        "# These are the column name that are selected to be stored in the tsv\n",
        "keyset = [\"created_at\", \"id\", \"id_str\", \"full_text\", \"source\", \"truncated\", \"in_reply_to_status_id\",\n",
        "          \"in_reply_to_status_id_str\", \"in_reply_to_user_id\", \"in_reply_to_user_id_str\", \n",
        "          \"in_reply_to_screen_name\", \"user\", \"coordinates\", \"place\", \"quoted_status_id\",\n",
        "          \"quoted_status_id_str\", \"is_quote_status\", \"quoted_status\", \"retweeted_status\", \n",
        "          \"quote_count\", \"reply_count\", \"retweet_count\", \"favorite_count\", \"entities\", \n",
        "          \"extended_entities\", \"favorited\", \"retweeted\", \"possibly_sensitive\", \"filter_level\", \n",
        "          \"lang\", \"matching_rules\", \"current_user_retweet\", \"scopes\", \"withheld_copyright\", \n",
        "          \"withheld_in_countries\", \"withheld_scope\", \"geo\", \"contributors\", \"display_text_range\",\n",
        "          \"quoted_status_permalink\"]\n",
        "hydrated_tweets = []\n",
        "# Reads the current tweets\n",
        "with jsonlines.open(output_json_filename, \"r\") as reader:\n",
        "    for i in reader.iter(type=dict, skip_invalid=True):\n",
        "        hydrated_tweets.append(i)\n",
        "# Writes them out\n",
        "with  open(output_filename, \"w+\") as output_file:\n",
        "    d = csv.DictWriter(output_file, keyset,delimiter='\\t') # if not working, change filename to .csv in and remove ,delimiter='\\t'\n",
        "    d.writeheader()\n",
        "    d.writerows(hydrated_tweets)\n",
        "\n",
        "print('\\n done!')"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YvxP0Hk-kbQ"
      },
      "source": [
        "Now the tsv should be in MegaCov folder."
      ]
    }
  ]
}